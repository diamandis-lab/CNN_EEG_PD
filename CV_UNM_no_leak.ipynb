{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of CV_UNM_no_leak.ipynb","provenance":[],"collapsed_sections":["XAQ3d3uKxJsl"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"XAQ3d3uKxJsl"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiKfckpmkll1","executionInfo":{"status":"ok","timestamp":1656354173440,"user_tz":240,"elapsed":22,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"276e1253-e033-4429-8184-9cbb7ca2db69"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jun 27 18:22:53 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IruP0niG1ieD","executionInfo":{"status":"ok","timestamp":1656354185393,"user_tz":240,"elapsed":11649,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"c9a31411-6623-40d5-e678-d82b20af2c92"},"source":["import matplotlib.pyplot as plt # for plotting\n","import seaborn as sns\n","import numpy as np # for transformation\n","\n","import torch # PyTorch package\n","import torchvision # load datasets\n","import torchvision.transforms as transforms # transform data\n","import torch.nn as nn # basic building block for neural neteorks\n","import torch.nn.functional as F # import convolution functions like Relu\n","import torch.optim as optim # optimzer\n","from torch.autograd import Variable \n","\n","#!pip install pandas==1.3.0 #1.3.0\n","import pandas as pd\n","\n","import glob\n","!pip3 install pickle5\n","import pickle5 as pickle\n","import os\n","\n","from torch.utils.data import Dataset, DataLoader, random_split, Subset, RandomSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","from tqdm import tqdm\n","#from pandas.core.computation.check import NUMEXPR_INSTALLED"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pickle5\n","  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n","\u001b[K     |████████████████████████████████| 256 kB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: pickle5\n","Successfully installed pickle5-0.0.12\n"]}]},{"cell_type":"markdown","metadata":{"id":"S5N6nu8J1Lxm"},"source":["### Five Key Steps\n","#### 1. Load and normalize the train and test data \n","#### 2.Define the Convolutional Neural Network (CNN)\n","#### 3. Define the loss function and optimizer\n","#### 4. Train the model on the train data\n","#### 5. Test the model on the test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydk5L0T-q4hp","executionInfo":{"status":"ok","timestamp":1656354208656,"user_tz":240,"elapsed":23287,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"4bef4f96-8a04-4b3e-fd8a-1562df81a08d"},"source":["#Mount Drive to get data\n","from google.colab import drive \n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"ETg82SWjBncW"},"source":["#set the device to cuda:0 \n","if torch.cuda.is_available():  \n","  device = \"cuda:0\" \n","else:  \n","  device = \"cpu\"  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"Szi_8kX2xQT_"}},{"cell_type":"code","metadata":{"id":"TgFrF_5Fo5-D"},"source":["#Load In the Dataset\n","class EEGDataset(Dataset):\n","\n","  def __init__(self, data_path, chunk_size=1000):\n","    \"\"\"\n","        Args:\n","            data_path (string): Directory with the EEG training data. Filenames in this dir must begin with \"PD\" or \"Control\" to assign labels correctly. Must be in .csv files. \n","            chunk_size (int): Number of datapoints from EEG time series to be included in a single non-overlapping epoch. Note that UNM data was collected at 500Hz.\n","    \"\"\"\n","    #create a list of datafields to keep. The electrodes given here are those in common to both the UI and UNM datasets.\n","    self.common_electrodes = ['time', 'Fp1', 'Fz', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'FCz', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'POz', 'PO8', 'P6', 'P2', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'F2', 'AF4', 'AF8']\n","\n","    #create the datapaths\n","    self.data_path = data_path  \n","    self.data_list = glob.glob(self.data_path + \"*.csv\")\n","\n","    #create containers for the data and labels respectively\n","    self.df_list = []\n","    self.label_list = []\n","\n","    self.files = glob.glob(self.data_path+ '*.csv')\n","\n","    for file in self.files:\n","\n","      if os.path.isfile(file):\n","\n","        \n","        csv = pd.read_csv(file,sep=',', index_col=[0])\n","        csv = csv.drop(index=0, inplace=False, axis=0) #drop first row because it's usually noisy\n","        csv = csv[self.common_electrodes]\n","        csv = csv.drop('time', inplace=False, axis=1) #drop time so it is not considered as a variable\n","\n","        #csv is then segmented into epochs. Each epochs is added as a df to the list of data with a corresponding list of labels (at this point the whole filename is given as the label).\n","        for chunk in range(1,csv.shape[0]//chunk_size +1):\n","            start = (chunk-1)*chunk_size\n","            stop = chunk*chunk_size\n","            self.df_list.append(csv.iloc[start:stop])\n","            self.label_list.append(file)\n","\n","    print('there are this many items in the list of data ' ,len(self.df_list))  \n","    print('there are this many items in the list of labels ' , len(self.label_list))\n","\n","    #define the labels as vectors\n","    self.class_map = {\"CTL\" : [0, 1], \"PD\": [1, 0]} \n","    \n","    \n","    #################### Normalization ###############################\n","    self.all_data = self.df_list[0]\n","    \n","    self.normalized_df_list = []\n","    \n","    #iterate through each epoch\n","    for df_index in range(0,len(self.df_list)):\n","      \n","      temp_df = self.df_list[df_index]\n","      mean_by_channel = []\n","      std_by_channel = []\n","      \n","      #determine normalization parameters by column (i.e. for each channel)\n","      for column in temp_df:\n","        mean_by_channel.append(temp_df[column].mean())\n","        std_by_channel.append(temp_df[column].std())\n","\n","      #apply normalization\n","      temp_df = temp_df.sub(mean_by_channel, axis='columns')\n","      temp_df = temp_df.div(std_by_channel, axis='columns')\n","      self.normalized_df_list.append(temp_df)\n","\n","    assert (len(std_by_channel)== len(mean_by_channel)), 'length of mean normalization and std normalization are not same length'\n","    print('The length of the lists of channels means and stds is ', len(mean_by_channel))\n","    assert ((self.normalized_df_list[0].shape)==(self.df_list[0].shape) and (len(self.normalized_df_list)==len(self.df_list))), 'Normalization changed the shape of the df_list'\n","    \n","\n","  #this is a required function that tells you how many data points you have in the dataset\n","  def __len__(self):\n","      return len(self.normalized_df_list) \n","\n","  #this is a required function that allows you to obtain a single data point according to its index\n","  def __getitem__(self, idx):\n","    \n","    #each dataframe represents one block id\n","    eeg_dataframe = self.normalized_df_list[idx]\n","    \n","    #determine whether that subject is control or PD\n","    filename = self.label_list[idx].split('/')[-1]\n","    #this is the string containing the filename. index first 2 chars to see if PD.\n","    if filename[0:2]=='PD': \n","      PD_label = 'PD'\n","    # then see if its control\n","    elif filename[0:7]=='Control':\n","      PD_label = 'CTL'\n","    # if neither, throw an error\n","    else:\n","      print(self.label_list[idx][0:2])\n","      print(self.label_list[idx][0:7])\n","      assert False, 'there is a problem finding the label'\n","\n","    #convert label to tensor using class map\n","    PD_label = torch.tensor(self.class_map[PD_label], dtype=torch.long)\n","    \n","    #reformat the eeg data\n","    eeg_tensor = torch.tensor(eeg_dataframe[0:chunk_size].values) #set an arbitrary length that cannot be shorter than any of your samples\n","    eeg_tensor = torch.permute(eeg_tensor,(1, 0))\n","    \n","    \n","    return eeg_tensor.float(), PD_label.float(), filename\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13XyUTKIA7FR"},"source":["## Define the Neural Network"]},{"cell_type":"code","metadata":{"id":"rzW834GxAnpM"},"source":["class PDNet(nn.Module):\n","\n","    def __init__(self,chunk_size=2500):\n","        super(PDNet, self).__init__()\n","        self.chunk_size = chunk_size\n","\n","        self.conv1 = nn.Conv1d(in_channels=60, out_channels=21, kernel_size=20,stride=1)\n","        self.norm1 = nn.BatchNorm1d(num_features=21)\n","        self.maxpool1 = nn.MaxPool1d(kernel_size=4,stride=4)\n","\n","        self.conv2 = nn.Conv1d(in_channels=21, out_channels=42, kernel_size=10,stride=1)\n","        self.norm2 = nn.BatchNorm1d(num_features=42)\n","        self.maxpool2 = nn.MaxPool1d(kernel_size=4,stride=4)\n","\n","        self.conv3 = nn.Conv1d(in_channels=42, out_channels=42, kernel_size=10,stride=1)\n","        self.norm3 = nn.BatchNorm1d(num_features=42)\n","        self.maxpool3 = nn.MaxPool1d(kernel_size=4,stride=4)\n","\n","        self.conv4 = nn.Conv1d(in_channels=42, out_channels=64, kernel_size=5,stride=1)\n","        self.norm4 = nn.BatchNorm1d(num_features=64)\n","        self.maxpool4 = nn.MaxPool1d(kernel_size=4,stride=4)\n","\n","        \n","        self.relu = nn.LeakyReLU(0.1)\n","\n","        \n","        self.fc1 = nn.Linear(in_features=448,out_features=256)#in_features=4*(self.chunk_size-8)\n","        self.dropout1 = nn.Dropout(p=0.5)\n","\n","        self.fc2 = nn.Linear(in_features=256, out_features=64)\n","        self.dropout2 = nn.Dropout(p=0.5)\n","\n","        self.fc3 = nn.Linear(in_features=64, out_features=16)\n","        self.fc4 = nn.Linear(in_features=16, out_features=2)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        \n","        x = self.relu(self.maxpool1(self.norm1(self.conv1(x))))\n","\n","        x = self.relu(self.maxpool2(self.norm2(self.conv2(x))))\n","        \n","        x = self.relu(self.maxpool3(self.norm3(self.conv3(x))))\n","        \n","        x = self.relu(self.maxpool4(self.norm4(self.conv4(x))))\n","        \n","        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimensi\n","        \n","        x = self.dropout1(self.fc1(x))\n","        x = self.dropout2(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        x = self.softmax(self.fc4(x))\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tdurir2WpjG-","executionInfo":{"status":"ok","timestamp":1656355460899,"user_tz":240,"elapsed":8,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"63d6f82b-c2c1-4fd1-c573-54284d672b53"},"source":["#test the input and output shapes\n","input_tensor = torch.rand([8,60,2500]).cuda() #of the form [batch_size, channels, epoch_length]\n","print(input_tensor.size())\n","network = PDNet().cuda()\n","output_tensor = network(input_tensor)\n","print((output_tensor.shape))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 60, 2500])\n","torch.Size([8, 2])\n"]}]},{"cell_type":"markdown","metadata":{"id":"iUPI71bjGAYw"},"source":["## Train and Validate Methods"]},{"cell_type":"code","metadata":{"id":"bPii7fjkF2By"},"source":["def train(train_dataloader, val_dataloader, epochs=23, learning_rate=0.0001, num_workers=2,  threshold=0.5):\n","    '''\n","      INPUTS:\n","        model(nn.Module): here we will pass PDNet to the training loop.\n","        train_dataloader(Dataloader): here we will pass the torch.utils.dataloader.Dataloader containing all the training batches. \n","        val_dataloader(Dataloader): here we will pass the torch.utils.dataloader.Dataloader containing all the validation batches. \n","        epochs(int): the total number of epochs to train for\n","        learning_rate(float): training hyperparameter defines the rate at which the optimizer will learn\n","        \n","      OUTPUTS:\n","        TP, FP, TN, FN (int): confusion matrix\n","        vote (str): correct/incorrect\n","    '''\n","    #create a model\n","    model = PDNet(chunk_size=chunk_size).to(device)\n","    model.train()\n","\n","    #define loss function and optimizer\n","    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.5,0.5]).cuda())\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    #start a timer\n","    start = torch.cuda.Event(enable_timing=True)\n","    end = torch.cuda.Event(enable_timing=True)\n","\n","    start.record()\n","    counter = 0\n","\n","    ########################## Training ########################################\n","    for epoch in range(epochs):  # loop over the dataset multiple times\n","        \n","        running_loss = 0.0\n","        counter = 0\n","        \n","        for i, data in enumerate(train_dataloader, 0):\n","            \n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels, filename = data\n","            inputs, labels = torch.permute(inputs,(0,1,2)).to(device), labels.to(torch.float32).to(device) #send them to the GPU\n","            \n","            batch_size = inputs.shape[0]\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","            #labels = int(labels)\n","            # forward \n","            outputs = model(inputs)\n","\n","            #Regularization Replaces pow(2.0) with abs() for L1 regularization\n","    \n","            l2_lambda = 0.001\n","            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","                  \n","            #loss + backward + optimize\n","            loss = criterion(outputs,labels) + l2_lambda*l2_norm\n","            loss.backward()\n","            optimizer.step()\n","            \n","            running_loss += loss.item()\n","            counter += 1\n","        \n","    ################################ Validation ##############################\n","    model.eval()\n","    TP, FP, TN, FN = 0, 0, 0, 0\n","\n","    for i, data in enumerate(val_dataloader, 0):\n","\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels, filename = data\n","        inputs, labels = torch.permute(inputs,(0,1,2)).to(device), labels.to(torch.float32).to(device) #send them to the GPU\n","              \n","        batch_size = inputs.shape[0]\n","\n","        #forward\n","        output = model(inputs)\n","\n","        #binarize output\n","        output[output>threshold] = 1\n","        output[output<=threshold] = 0        \n","\n","        #designate each sample to a confusion matrix label\n","        for j in range(0,len(output)):\n","          if (output[j-1,0] == 1) and (labels[j-1,0] == 1):\n","              TP += 1\n","          elif(output[j-1,0]==1) and (labels[j-1,0] == 0 ):\n","              FP += 1\n","          elif(output[j-1,0]==0) and (labels[j-1,0]== 1):\n","              FN += 1\n","          elif(output[j-1,0]==0) and (labels[j-1,0]== 0):\n","              TN += 1\n","\n","    #determine whether this subject was predicted correct or incorrect by majority vote\n","    if (TP + TN) > (FP + FN):\n","      vote = 'Correct'\n","    elif (TP + TN) < (FP + FN):\n","      vote = 'Incorrect'\n","    else:\n","      vote ='Unsure'\n","\n","    # whatever you are timing goes here\n","    end.record()\n","\n","    # Waits for everything to finish running\n","    torch.cuda.synchronize()\n","\n","    print('The vote was: ', vote)\n","    print('True Positives: ', TP)\n","    print('False Positives: ',FP)\n","    print('True Negatives: ', TN)\n","    print('False Negatives: ', FN)\n","\n","    return TP, FP, TN, FN, vote\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlGDWXAuBrQu"},"source":["#testing the performance\n","def validate(model, valloader, threshold=0.5, batch_size=8):\n","\n","  total_loss = 0\n","  true_positives = 0\n","  true_negatives = 0\n","  false_positives = 0\n","  false_negatives = 0\n","\n","  true_labels = []\n","  counter = 0\n","\n","  #This loads a batch at time\n","  for i, data in enumerate(valloader, 0):\n","    #read in data\n","    inputs, labels, filename = data\n","    inputs, labels = torch.permute(inputs,(0,1,2)).to(device), labels.to(torch.float32).to(device) #send them to the GPU\n","    \n","    #forward\n","    output = model(inputs)\n","    criterion = nn.CrossEntropyLoss() \n","    \n","    l2_lambda = 0.0001\n","    l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","\n","    total_loss += criterion(output,labels) + l2_lambda*l2_norm \n","    counter += 1\n","  \n","    output[output>threshold] = 1\n","    output[output<threshold] = 0\n","\n","    #designate each sample to a confusion matrix label\n","    for j in range(0,len(output)):\n","      if (output[j-1,0] == 1) and (labels[j-1,0] == 1):\n","          true_positives += 1\n","      elif(output[j-1,0]==1) and (labels[j-1,0] == 0 ):\n","          false_positives += 1\n","      elif(output[j-1,0]==0) and (labels[j-1,0]== 1):\n","          false_negatives += 1\n","      elif(output[j-1,0]==0) and (labels[j-1,0]== 0):\n","          true_negatives += 1\n","  \n","  print('true positives: ', true_positives)\n","  print('false positives: ',false_positives)\n","  print('true negatives: ',true_negatives)\n","  print('false negatives', false_negatives)    \n","  avg_loss = total_loss/counter \n","  print(\"the average validation loss value is: \", avg_loss.item())\n","  print('--------------------------------------------------')\n","\n","  return avg_loss.item()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Main Method/Call Training Loop"],"metadata":{"id":"tckmWneLxaCf"}},{"cell_type":"code","source":["############################ CREATE DATASET ################################\n","batch_size = 8\n","num_workers = 2\n","chunk_size = 2500\n","\n","#data locations for train/val data\n","data_src =  '/content/drive/MyDrive/UNM_Data/'\n","\n","############ create list of subject numbers to leave out ###############################\n","files = glob.glob(data_src + '*.csv')\n","leave_one_out_list = []\n","for file in files:  \n","  leave_one_out_list.append(file.split('/')[-1].split('_')[1])\n","\n","############# create dataset of all data ############################\n","EEG_whole_Dataset = EEGDataset(data_path=data_src, chunk_size=chunk_size)\n","\n","################################################3"],"metadata":{"id":"RHBRYaWp3iZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656355068425,"user_tz":240,"elapsed":108272,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"78fa36d9-c084-4818-9f38-fca412c1decd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["there are this many items in the list of data  2122\n","there are this many items in the list of labels  2122\n","The length of the lists of channels means and stds is  60\n"]}]},{"cell_type":"code","source":["##################### CROSS VALIDATION ##############\n","'''\n","Here, a for loop will iterate through every object in the whole dataset. Using the filename, it will determine the\n","subject number for the sample and make two subsets: validation using only the one subject number, and training using all other\n","subject numbers. It will repeat this for each subject number.\n","Epochs and Learning rate are adjustable below\n","'''\n","correct_votes, incorrect_votes, unsure_votes = 0,0,0\n","true_positives, false_positives, true_negatives, false_negatives = 0,0,0,0\n","\n","#leave_out will be \n","for leave_out in leave_one_out_list:\n","  print('Running a fold while leaving out: ', leave_out)\n","  to_be_removed = []\n","\n","  for index in range(len(EEG_whole_Dataset)):\n","    complete_list = range(len(EEG_whole_Dataset))\n","\n","    subset_ds = Subset(EEG_whole_Dataset, [index])\n","    sample_sampler = RandomSampler(subset_ds)\n","    subset_dataloader = DataLoader(subset_ds, sampler=sample_sampler, batch_size=1)\n","    data = next(iter(subset_dataloader))\n","    eeg_data, label, filename = data\n","    subj_id = filename[0].split('_')[1]\n","\n","    if subj_id == leave_out:\n","      \n","      to_be_removed.append(index)\n","\n","  to_be_kept = [x for x in complete_list if x not in to_be_removed]\n","\n","  train_dataset = Subset(EEG_whole_Dataset, to_be_kept)\n","  val_dataset = Subset(EEG_whole_Dataset, to_be_removed)\n","\n","  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n","  val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n","  del train_dataset, val_dataset #free up memory\n","\n","  TP, FP, TN, FN, vote = train(train_dataloader, val_dataloader, epochs=30, learning_rate=0.0001, threshold=0.5)\n","  true_positives += TP\n","  false_positives += FP\n","  true_negatives += TN\n","  false_negatives += FN\n","\n","  if vote == 'Correct':\n","    correct_votes += 1\n","  elif vote == 'Incorrect':\n","    incorrect_votes += 1\n","  else:\n","    unsure_votes +=1\n","\n","print('total correct subject classifications: ', correct_votes)\n","print('total incorrect subject classifications: ', incorrect_votes)\n","print('total unsure subject classifications: ',unsure_votes)\n","print('total true postives (epochs)', true_positives)\n","print('total false postives (epochs)', false_positives)\n","print('total true negatives (epochs)', true_negatives)\n","print('total false negatives (epochs)', false_negatives)\n","print('----------------------------------------------------------------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7UKK_kSQbrC4","outputId":"b2556752-e744-441b-e145-8cbc1060cc30","executionInfo":{"status":"error","timestamp":1656356836292,"user_tz":240,"elapsed":139221,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running a fold while leaving out:  801\n","The vote was:  Incorrect\n","True Positives:  14\n","False Positives:  0\n","True Negatives:  0\n","False Negatives:  20\n","Running a fold while leaving out:  802\n"]},{"output_type":"stream","name":"stderr","text":["Exception in thread Thread-54:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n","    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n","    return _ForkingPickler.loads(res)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 295, in rebuild_storage_fd\n","    fd = df.detach()\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n","    with _resource_sharer.get_connection(self._id) as conn:\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n","    c = Client(address, authkey=process.current_process().authkey)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 498, in Client\n","    answer_challenge(c, authkey)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 747, in answer_challenge\n","    response = connection.recv_bytes(256)        # reject large message\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","ConnectionResetError: [Errno 104] Connection reset by peer\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n","    send_bytes(obj)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n","    self._send_bytes(m[offset:offset + size])\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n","    self._send(header + buf)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n","    n = write(self._handle, buf)\n","BrokenPipeError: [Errno 32] Broken pipe\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-7f03334f2882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0mTP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m   \u001b[0mtrue_positives\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mTP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mfalse_positives\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-fb435f6e14bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, val_dataloader, epochs, learning_rate, num_workers, threshold)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_lambda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml2_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"K4gxuPCDgUAO"}},{"cell_type":"code","source":["def plot_confusion_matrix(TP, FP, TN, FN):\n","  pred = []\n","  true = []\n","\n","  for i in range(TP):\n","    pred.append(1)\n","    true.append(1)\n","  \n","  for i in range(FP):\n","    pred.append(1)\n","    true.append(0)\n","  \n","  for i in range(TN):\n","    pred.append(0)\n","    true.append(0)\n","\n","  for i in range(FN):\n","    pred.append(0)\n","    true.append(1)\n","\n","  plt.figure(figsize=(8,6))\n","  conf_matrix = (confusion_matrix(true, pred))\n","  # Using Seaborn heatmap to create the plot\n","  fx = sns.heatmap(conf_matrix,cmap='vlag',annot=True, annot_kws={'fontsize':15},fmt='g')\n","  \n","  # labels the title and x, y axis of plot\n","  #fx.set_title('Plotting Confusion Matrix using Seaborn\\n\\n');\n","  fx.set_xlabel('Predicted Values',size=16)\n","  fx.set_ylabel('Actual Values ', size=16);\n","\n","  # labels the boxes\n","  fx.xaxis.set_ticklabels(['CTL','PD'],size=15)\n","  fx.yaxis.set_ticklabels(['CTL','PD'],size=15)\n","\n","  plt.show()"],"metadata":{"id":"CYo91ovDgVIC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def plot_roc_auc(specificities, sensitivities):\n","  plt.figure(figsize=(10,8))\n","  plt.plot((1-np.array(specificities)),sensitivities);\n","  #plt.title('ROC Curve', size= 20);\n","  plt.xlabel('1-Specificity', size = 14);\n","  plt.ylabel('Sensitivity', size = 14);\n","  plt.legend(['CNN'])\n","  AUC = auc((1-np.array(specificities)),sensitivities)\n","  plt.text(0.7,0.2, 'AUC = %f'%AUC, fontsize=10)\n","  plt.show()\n"],"metadata":{"id":"mQAjYGGXgaXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_confusion_matrix(TP=739, FP=357, TN=730, FN=372)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"wtQrVWFVGUFl","executionInfo":{"status":"ok","timestamp":1656356677967,"user_tz":240,"elapsed":595,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"}},"outputId":"2dfce420-fa71-4c7d-91e2-4e22a42f8a53"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x432 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}